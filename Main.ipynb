{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "tr = pd.read_csv('train.csv')\n",
    "camp = pd.read_csv('campaign_data.csv')\n",
    "coup = pd.read_csv('coupon_item_mapping.csv')\n",
    "item = pd.read_csv('item_data.csv')\n",
    "cust_dem = pd.read_csv('customer_demographics.csv')\n",
    "cust_trans = pd.read_csv('customer_transaction_data.csv')\n",
    "ts = pd.read_csv('test_QyjYwdj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading cutomer level, coupon level & cmapaign level aggregation data which we prepared earlier\n",
    "cust_agg = pd.read_csv('cust_agg.csv')\n",
    "coup_agg = pd.read_csv('coup_agg.csv')\n",
    "camp_agg = pd.read_csv('camp_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 760 entries, 0 to 759\n",
      "Data columns (total 7 columns):\n",
      "customer_id       760 non-null int64\n",
      "age_range         760 non-null object\n",
      "marital_status    431 non-null object\n",
      "rented            760 non-null int64\n",
      "family_size       760 non-null object\n",
      "no_of_children    222 non-null object\n",
      "income_bracket    760 non-null int64\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 41.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking customer demographics data\n",
    "cust_dem.info()\n",
    "#Two columns have missing values\n",
    "\n",
    "#More than 40% of data is missing in marital_status & no_of_children. We can treat them as 'NA'\n",
    "cust_dem.fillna(value={'marital_status':'NA', 'no_of_children':'NA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merginf customer demographics details to train and test dataset\n",
    "tr = tr.merge(cust_dem, on='customer_id', how='left')\n",
    "ts = ts.merge(cust_dem, on='customer_id', how='left')\n",
    "\n",
    "#Also changing negative foramt in discount to positive\n",
    "cust_trans['coupon_discount'] = abs(cust_trans['coupon_discount'])\n",
    "cust_trans['other_discount'] = abs(cust_trans['other_discount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting start and end date to datetime format\n",
    "camp['start_date'] = pd.to_datetime(camp['start_date'], infer_datetime_format=True, dayfirst=True)\n",
    "camp['end_date'] = pd.to_datetime(camp['end_date'], infer_datetime_format=True, dayfirst=True)\n",
    "#Getting duration of campaign in days\n",
    "camp['camp_duration_days'] = (camp['end_date'] - camp['start_date']).dt.days+1\n",
    "\n",
    "#Getting duration of campaign in weeks\n",
    "camp['camp_duration_weeks'] = round(((camp['end_date'] - camp['start_date']).dt.days+1)/7)\n",
    "\n",
    "#Getting start_date & end_date month\n",
    "camp['camp_start_month'] = camp['start_date'].dt.month\n",
    "camp['camp_end_month'] = camp['end_date'].dt.month\n",
    "\n",
    "#Getting start_date & end_date Quarter\n",
    "camp['camp_start_quarter'] = camp['start_date'].dt.quarter\n",
    "camp['camp_end_quarter'] = camp['end_date'].dt.quarter\n",
    "\n",
    "#Getting start_day & end_day year\n",
    "camp['camp_start_year'] = camp['start_date'].dt.year\n",
    "camp['camp_end_year'] = camp['end_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Campaign data with train and test dataset\n",
    "tr = tr.merge(camp, on='campaign_id', how='left').drop(['start_date', 'end_date'], axis='columns')\n",
    "ts = ts.merge(camp, on='campaign_id', how='left').drop(['start_date', 'end_date'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Encoding on training data\n",
    "def MeanEncoding(df, col, trgt, alpha=5, splits=4):\n",
    "    mean_g = tr[trgt].mean()\n",
    "    newcol = col+'_Enc'\n",
    "    df[newcol] = np.nan\n",
    "    kf = KFold(n_splits=splits, random_state=100, shuffle=True)\n",
    "    for tr_idx, ts_idx in kf.split(tr):\n",
    "        enc_tr = df.loc[tr_idx]\n",
    "        enc_ts = df.loc[ts_idx]\n",
    "        map_enc = enc_tr.groupby([col])[trgt].describe().apply(lambda x: ((x['count']*x['mean'])+(mean_g*alpha))/\\\n",
    "                                                               (x['count']+alpha), axis=1)\n",
    "        df.loc[ts_idx, newcol] = enc_ts[col].map(map_enc)\n",
    "        \n",
    "    df[newcol] = df[newcol].astype('float')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Encoding with 4folds and regularisation parameter(alpha) as 5\n",
    "col_list =['campaign_id', 'coupon_id', 'customer_id', 'age_range', 'rented',\n",
    "           'family_size', 'income_bracket', 'campaign_type',\n",
    "           'camp_start_month', 'camp_end_month', 'camp_start_quarter',\n",
    "           'camp_end_quarter', 'camp_start_year', 'camp_end_year', 'marital_status', 'no_of_children']\n",
    "\n",
    "trgt = 'redemption_status'\n",
    "\n",
    "for x in col_list:\n",
    "    newcol = x+'_Enc'\n",
    "    ts[newcol] = np.nan\n",
    "    tr = MeanEncoding(tr, col=x, trgt=trgt)    \n",
    "    map_enc = tr.groupby([x])[newcol].mean()\n",
    "    ts[newcol] = ts[x].map(map_enc)\n",
    "    ts[newcol] = ts[newcol].astype('float')\n",
    "    tr.loc[tr[newcol].isnull(), newcol] = tr[trgt].mean()\n",
    "    ts.loc[ts[newcol].isnull(), newcol] = tr[trgt].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new features based on coupon id and customer id combination in training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_item = cust_trans.merge(item, on='item_id', how='left')\n",
    "coup_item = coup.merge(item, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUmber of items bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[['customer_id', 'item_id']].drop_duplicates()\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['item_id'].nunique().reset_index()\n",
    "tmp.rename(columns={'item_id': 'coupcust_items_bought'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_items_bought'].isnull(), 'coupcust_items_bought']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_items_bought'].isnull(), 'coupcust_items_bought']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total quantities bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_quantity_sum'].isnull(), 'coupcust_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_quantity_sum'].isnull(), 'coupcust_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of total transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_trans_count'].isnull(), 'coupcust_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_trans_count'].isnull(), 'coupcust_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of coupon discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[cust_item['coupon_discount']!=0][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_coupdisc_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_coupdisc_trans_count'].isnull(), 'coupcust_coupdisc_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_coupdisc_trans_count'].isnull(), 'coupcust_coupdisc_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of other discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[cust_item['other_discount']!=0][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_otherdisc_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_otherdisc_trans_count'].isnull(), 'coupcust_otherdisc_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_otherdisc_trans_count'].isnull(), 'coupcust_otherdisc_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['other_discount']!=0) | (cust_item['coupon_discount']!=0)][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_discount_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_discount_trans_count'].isnull(), 'coupcust_discount_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_discount_trans_count'].isnull(), 'coupcust_discount_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cname1 = 'coupcust_trans_count'\n",
    "cname2 = 'coupcust_coupdisc_trans_count'\n",
    "cname3 = 'coupcust_otherdisc_trans_count'\n",
    "cname4 = 'coupcust_discount_trans_count'\n",
    "cname5 = 'coupcust_coupdisc_trans_perc'\n",
    "cname6 = 'coupcust_otherdisc_trans_perc'\n",
    "cname7 = 'coupcust_discount_trans_perc'\n",
    "\n",
    "tr[cname5] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "ts[cname5] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "\n",
    "tr[cname6] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "ts[cname6] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "\n",
    "tr[cname7] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)\n",
    "ts[cname7] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total quantities for coupon discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[cust_item['coupon_discount']!=0][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_coupdisc_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_coupdisc_quantity_sum'].isnull(), 'coupcust_coupdisc_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_coupdisc_quantity_sum'].isnull(), 'coupcust_coupdisc_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total quantities for other discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[cust_item['other_discount']!=0][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_otherdisc_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_otherdisc_quantity_sum'].isnull(), 'coupcust_otherdisc_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_otherdisc_quantity_sum'].isnull(), 'coupcust_otherdisc_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total quantities for discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['other_discount']!=0) | (cust_item['coupon_discount']!=0)][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_discount_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_discount_quantity_sum'].isnull(), 'coupcust_discount_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_discount_quantity_sum'].isnull(), 'coupcust_discount_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cname1 = 'coupcust_quantity_sum'\n",
    "cname2 = 'coupcust_coupdisc_quantity_sum'\n",
    "cname3 = 'coupcust_otherdisc_quantity_sum'\n",
    "cname4 = 'coupcust_discount_quantity_sum'\n",
    "cname5 = 'coupcust_coupdisc_quantity_perc'\n",
    "cname6 = 'coupcust_otherdisc_quantity_perc'\n",
    "cname7 = 'coupcust_discount_quantity_perc'\n",
    "\n",
    "tr[cname5] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "ts[cname5] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "\n",
    "tr[cname6] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "ts[cname6] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "\n",
    "tr[cname7] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)\n",
    "ts[cname7] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total selling price for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[['customer_id', 'item_id', 'selling_price']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['selling_price'].sum().reset_index()\n",
    "tmp.rename(columns={'selling_price': 'coupcust_selling_price_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_selling_price_sum'].isnull(), 'coupcust_selling_price_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_selling_price_sum'].isnull(), 'coupcust_selling_price_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total coupon discount for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[['customer_id', 'item_id', 'coupon_discount']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['coupon_discount'].sum().reset_index()\n",
    "tmp.rename(columns={'coupon_discount': 'coupcust_coupon_discount_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_coupon_discount_sum'].isnull(), 'coupcust_coupon_discount_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_coupon_discount_sum'].isnull(), 'coupcust_coupon_discount_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total other discount for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[['customer_id', 'item_id', 'other_discount']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['other_discount'].sum().reset_index()\n",
    "tmp.rename(columns={'other_discount': 'coupcust_other_discount_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_other_discount_sum'].isnull(), 'coupcust_other_discount_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_other_discount_sum'].isnull(), 'coupcust_other_discount_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cname1 = 'coupcust_selling_price_sum'\n",
    "cname2 = 'coupcust_coupon_discount_sum'\n",
    "cname3 = 'coupcust_other_discount_sum'\n",
    "cname4 = 'coupcust_coupdisc_price_perc'\n",
    "cname5 = 'coupcust_otherdisc_price_perc'\n",
    "cname6 = 'coupcust_discount_price_perc'\n",
    "\n",
    "tr[cname4] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "ts[cname4] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "\n",
    "tr[cname5] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "ts[cname5] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "\n",
    "tr[cname6] = tr.apply(lambda x: 0 if (x[cname1]==0) else (x[cname2]+x[cname3])/x[cname1], axis=1)\n",
    "ts[cname6] = ts.apply(lambda x: 0 if (x[cname1]==0) else (x[cname2]+x[cname3])/x[cname1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Local items bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')][['customer_id', 'item_id']].drop_duplicates()\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['item_id'].nunique().reset_index()\n",
    "tmp.rename(columns={'item_id': 'coupcust_Local_items_bought'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_items_bought'].isnull(), 'coupcust_Local_items_bought']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_items_bought'].isnull(), 'coupcust_Local_items_bought']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Established items bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')][['customer_id', 'item_id']].drop_duplicates()\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['item_id'].nunique().reset_index()\n",
    "tmp.rename(columns={'item_id': 'coupcust_Established_items_bought'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_items_bought'].isnull(), 'coupcust_Established_items_bought']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_items_bought'].isnull(), 'coupcust_Established_items_bought']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of total Local transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Local_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_trans_count'].isnull(), 'coupcust_Local_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_trans_count'].isnull(), 'coupcust_Local_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of total Established transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Established_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_trans_count'].isnull(), 'coupcust_Established_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_trans_count'].isnull(), 'coupcust_Established_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Local coupon discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')& (cust_item['coupon_discount']!=0)][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Local_coupdisc_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_coupdisc_trans_count'].isnull(), 'coupcust_Local_coupdisc_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_coupdisc_trans_count'].isnull(), 'coupcust_Local_coupdisc_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Established coupon discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')& (cust_item['coupon_discount']!=0)][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Established_coupdisc_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_coupdisc_trans_count'].isnull(), 'coupcust_Established_coupdisc_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_coupdisc_trans_count'].isnull(), 'coupcust_Established_coupdisc_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Local other discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')& (cust_item['other_discount']!=0)][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Local_otherdisc_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_otherdisc_trans_count'].isnull(), 'coupcust_Local_otherdisc_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_otherdisc_trans_count'].isnull(), 'coupcust_Local_otherdisc_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Established other discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')& (cust_item['other_discount']!=0)][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Established_otherdisc_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_otherdisc_trans_count'].isnull(), 'coupcust_Established_otherdisc_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_otherdisc_trans_count'].isnull(), 'coupcust_Established_otherdisc_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Local discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local') &\n",
    "               ((cust_item['other_discount']!=0)|(cust_item['coupon_discount']!=0))][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Local_discount_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_discount_trans_count'].isnull(), 'coupcust_Local_discount_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_discount_trans_count'].isnull(), 'coupcust_Local_discount_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Established discount transactions by the customer for the items in that particular coupon code\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established') &\n",
    "               ((cust_item['other_discount']!=0)|(cust_item['coupon_discount']!=0))][['customer_id', 'item_id']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id']).size().rename('coupcust_Established_discount_trans_count').reset_index()\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_discount_trans_count'].isnull(), 'coupcust_Established_discount_trans_count']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_discount_trans_count'].isnull(), 'coupcust_Established_discount_trans_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_l = ['Local', 'Established']\n",
    "for x in br_l:\n",
    "    cname1 = 'coupcust_'+str(x)+'_trans_count'\n",
    "    cname2 = 'coupcust_'+str(x)+'_coupdisc_trans_count'\n",
    "    cname3 = 'coupcust_'+str(x)+'_otherdisc_trans_count'\n",
    "    cname4 = 'coupcust_'+str(x)+'_discount_trans_count'\n",
    "    cname5 = 'coupcust_'+str(x)+'_coupdisc_trans_perc'\n",
    "    cname6 = 'coupcust_'+str(x)+'_otherdisc_trans_perc'\n",
    "    cname7 = 'coupcust_'+str(x)+'_discount_trans_perc'\n",
    "    \n",
    "    tr[cname5] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "    ts[cname5] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "    \n",
    "    tr[cname6] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "    ts[cname6] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "    \n",
    "    tr[cname7] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)\n",
    "    ts[cname7] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local item quantities bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Local_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_quantity_sum'].isnull(), 'coupcust_Local_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_quantity_sum'].isnull(), 'coupcust_Local_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Established item quantities bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Established_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_quantity_sum'].isnull(), 'coupcust_Established_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_quantity_sum'].isnull(), 'coupcust_Established_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local quantities for coupon discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local') &\n",
    "               (cust_item['coupon_discount']!=0)][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Local_coupdisc_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_coupdisc_quantity_sum'].isnull(), 'coupcust_Local_coupdisc_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_coupdisc_quantity_sum'].isnull(), 'coupcust_Local_coupdisc_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Established quantities for coupon discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established') &\n",
    "               (cust_item['coupon_discount']!=0)][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Established_coupdisc_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_coupdisc_quantity_sum'].isnull(), 'coupcust_Established_coupdisc_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_coupdisc_quantity_sum'].isnull(), 'coupcust_Established_coupdisc_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local quantities for other discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local') &\n",
    "               (cust_item['other_discount']!=0)][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Local_otherdisc_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_otherdisc_quantity_sum'].isnull(), 'coupcust_Local_otherdisc_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_otherdisc_quantity_sum'].isnull(), 'coupcust_Local_otherdisc_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Established quantities for other discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established') &\n",
    "               (cust_item['other_discount']!=0)][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Established_otherdisc_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_otherdisc_quantity_sum'].isnull(), 'coupcust_Established_otherdisc_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_otherdisc_quantity_sum'].isnull(), 'coupcust_Established_otherdisc_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local quantities for discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local') & \n",
    "               ((cust_item['other_discount']!=0) | (cust_item['coupon_discount']!=0))][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Local_discount_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_discount_quantity_sum'].isnull(), 'coupcust_Local_discount_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_discount_quantity_sum'].isnull(), 'coupcust_Local_discount_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local quantities for discount transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established') & \n",
    "               ((cust_item['other_discount']!=0) | (cust_item['coupon_discount']!=0))][['customer_id', 'item_id', 'quantity']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['quantity'].sum().reset_index()\n",
    "tmp.rename(columns={'quantity': 'coupcust_Established_discount_quantity_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_discount_quantity_sum'].isnull(), 'coupcust_Established_discount_quantity_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_discount_quantity_sum'].isnull(), 'coupcust_Established_discount_quantity_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_l = ['Local', 'Established']\n",
    "for x in br_l:\n",
    "    cname1 = 'coupcust_'+str(x)+'_quantity_sum'\n",
    "    cname2 = 'coupcust_'+str(x)+'_coupdisc_quantity_sum'\n",
    "    cname3 = 'coupcust_'+str(x)+'_otherdisc_quantity_sum'\n",
    "    cname4 = 'coupcust_'+str(x)+'_discount_quantity_sum'\n",
    "    cname5 = 'coupcust_'+str(x)+'_coupdisc_quantity_perc'\n",
    "    cname6 = 'coupcust_'+str(x)+'_otherdisc_quantity_perc'\n",
    "    cname7 = 'coupcust_'+str(x)+'_discount_quantity_perc'\n",
    "    \n",
    "    tr[cname5] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "    ts[cname5] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "    \n",
    "    tr[cname6] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "    ts[cname6] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "    \n",
    "    tr[cname7] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)\n",
    "    ts[cname7] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname4]/x[cname1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local selling price for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')][['customer_id', 'item_id', 'selling_price']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['selling_price'].sum().reset_index()\n",
    "tmp.rename(columns={'selling_price': 'coupcust_Local_selling_price_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_selling_price_sum'].isnull(), 'coupcust_Local_selling_price_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_selling_price_sum'].isnull(), 'coupcust_Local_selling_price_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Established selling price for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')][['customer_id', 'item_id', 'selling_price']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['selling_price'].sum().reset_index()\n",
    "tmp.rename(columns={'selling_price': 'coupcust_Established_selling_price_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_selling_price_sum'].isnull(), 'coupcust_Established_selling_price_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_selling_price_sum'].isnull(), 'coupcust_Established_selling_price_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local coupon discount for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')][['customer_id', 'item_id', 'coupon_discount']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['coupon_discount'].sum().reset_index()\n",
    "tmp.rename(columns={'coupon_discount': 'coupcust_Local_coupon_discount_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_coupon_discount_sum'].isnull(), 'coupcust_Local_coupon_discount_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_coupon_discount_sum'].isnull(), 'coupcust_Local_coupon_discount_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Established coupon discount for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')][['customer_id', 'item_id', 'coupon_discount']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['coupon_discount'].sum().reset_index()\n",
    "tmp.rename(columns={'coupon_discount': 'coupcust_Established_coupon_discount_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_coupon_discount_sum'].isnull(), 'coupcust_Established_coupon_discount_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_coupon_discount_sum'].isnull(), 'coupcust_Established_coupon_discount_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Local other discount for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Local')][['customer_id', 'item_id', 'other_discount']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['other_discount'].sum().reset_index()\n",
    "tmp.rename(columns={'other_discount': 'coupcust_Local_other_discount_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Local_other_discount_sum'].isnull(), 'coupcust_Local_other_discount_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Local_other_discount_sum'].isnull(), 'coupcust_Local_other_discount_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total Established other discount for all transactions bought by the customer which were in that particular coupon code?\n",
    "x = pd.concat([tr, ts], sort=False, axis='rows')[['coupon_id', 'customer_id']].drop_duplicates()\n",
    "x1 = cust_item[(cust_item['brand_type']=='Established')][['customer_id', 'item_id', 'other_discount']]\n",
    "x2 = coup_item[['coupon_id', 'item_id']]\n",
    "x3 = x2.merge(x1, on='item_id', how='inner')\n",
    "tmp = x3.groupby(['coupon_id', 'customer_id'])['other_discount'].sum().reset_index()\n",
    "tmp.rename(columns={'other_discount': 'coupcust_Established_other_discount_sum'}, inplace=True)\n",
    "tr = tr.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "tr.loc[tr['coupcust_Established_other_discount_sum'].isnull(), 'coupcust_Established_other_discount_sum']=0\n",
    "ts = ts.merge(tmp, on=['coupon_id','customer_id'], how='left')\n",
    "ts.loc[ts['coupcust_Established_other_discount_sum'].isnull(), 'coupcust_Established_other_discount_sum']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_l = ['Local', 'Established']\n",
    "for x in br_l:\n",
    "    cname1 = 'coupcust_'+str(x)+'_selling_price_sum'\n",
    "    cname2 = 'coupcust_'+str(x)+'_coupon_discount_sum'\n",
    "    cname3 = 'coupcust_'+str(x)+'_other_discount_sum'\n",
    "    cname4 = 'coupcust_'+str(x)+'_coupdisc_price_perc'\n",
    "    cname5 = 'coupcust_'+str(x)+'_otherdisc_price_perc'\n",
    "    cname6 = 'coupcust_'+str(x)+'_discount_price_perc'\n",
    "\n",
    "    tr[cname4] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "    ts[cname4] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname2]/x[cname1], axis=1)\n",
    "\n",
    "    tr[cname5] = tr.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "    ts[cname5] = ts.apply(lambda x: 0 if (x[cname1]==0) else x[cname3]/x[cname1], axis=1)\n",
    "\n",
    "    tr[cname6] = tr.apply(lambda x: 0 if (x[cname1]==0) else (x[cname2]+x[cname3])/x[cname1], axis=1)\n",
    "    ts[cname6] = ts.apply(lambda x: 0 if (x[cname1]==0) else (x[cname2]+x[cname3])/x[cname1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'campaign_id', 'coupon_id', 'customer_id', 'redemption_status',\n",
       "       'age_range', 'marital_status', 'rented', 'family_size',\n",
       "       'no_of_children', 'income_bracket', 'campaign_type',\n",
       "       'camp_duration_days', 'camp_duration_weeks', 'camp_start_month',\n",
       "       'camp_end_month', 'camp_start_quarter', 'camp_end_quarter',\n",
       "       'camp_start_year', 'camp_end_year', 'campaign_id_Enc', 'coupon_id_Enc',\n",
       "       'customer_id_Enc', 'age_range_Enc', 'rented_Enc', 'family_size_Enc',\n",
       "       'income_bracket_Enc', 'campaign_type_Enc', 'camp_start_month_Enc',\n",
       "       'camp_end_month_Enc', 'camp_start_quarter_Enc', 'camp_end_quarter_Enc',\n",
       "       'camp_start_year_Enc', 'camp_end_year_Enc', 'marital_status_Enc',\n",
       "       'no_of_children_Enc', 'coupcust_items_bought', 'coupcust_quantity_sum',\n",
       "       'coupcust_trans_count', 'coupcust_coupdisc_trans_count',\n",
       "       'coupcust_otherdisc_trans_count', 'coupcust_discount_trans_count',\n",
       "       'coupcust_coupdisc_trans_perc', 'coupcust_otherdisc_trans_perc',\n",
       "       'coupcust_discount_trans_perc', 'coupcust_coupdisc_quantity_sum',\n",
       "       'coupcust_otherdisc_quantity_sum', 'coupcust_discount_quantity_sum',\n",
       "       'coupcust_coupdisc_quantity_perc', 'coupcust_otherdisc_quantity_perc',\n",
       "       'coupcust_discount_quantity_perc', 'coupcust_selling_price_sum',\n",
       "       'coupcust_coupon_discount_sum', 'coupcust_other_discount_sum',\n",
       "       'coupcust_coupdisc_price_perc', 'coupcust_otherdisc_price_perc',\n",
       "       'coupcust_discount_price_perc', 'coupcust_Local_items_bought',\n",
       "       'coupcust_Established_items_bought', 'coupcust_Local_trans_count',\n",
       "       'coupcust_Established_trans_count',\n",
       "       'coupcust_Local_coupdisc_trans_count',\n",
       "       'coupcust_Established_coupdisc_trans_count',\n",
       "       'coupcust_Local_otherdisc_trans_count',\n",
       "       'coupcust_Established_otherdisc_trans_count',\n",
       "       'coupcust_Local_discount_trans_count',\n",
       "       'coupcust_Established_discount_trans_count',\n",
       "       'coupcust_Local_coupdisc_trans_perc',\n",
       "       'coupcust_Local_otherdisc_trans_perc',\n",
       "       'coupcust_Local_discount_trans_perc',\n",
       "       'coupcust_Established_coupdisc_trans_perc',\n",
       "       'coupcust_Established_otherdisc_trans_perc',\n",
       "       'coupcust_Established_discount_trans_perc',\n",
       "       'coupcust_Local_quantity_sum', 'coupcust_Established_quantity_sum',\n",
       "       'coupcust_Local_coupdisc_quantity_sum',\n",
       "       'coupcust_Established_coupdisc_quantity_sum',\n",
       "       'coupcust_Local_otherdisc_quantity_sum',\n",
       "       'coupcust_Established_otherdisc_quantity_sum',\n",
       "       'coupcust_Local_discount_quantity_sum',\n",
       "       'coupcust_Established_discount_quantity_sum',\n",
       "       'coupcust_Local_coupdisc_quantity_perc',\n",
       "       'coupcust_Local_otherdisc_quantity_perc',\n",
       "       'coupcust_Local_discount_quantity_perc',\n",
       "       'coupcust_Established_coupdisc_quantity_perc',\n",
       "       'coupcust_Established_otherdisc_quantity_perc',\n",
       "       'coupcust_Established_discount_quantity_perc',\n",
       "       'coupcust_Local_selling_price_sum',\n",
       "       'coupcust_Established_selling_price_sum',\n",
       "       'coupcust_Local_coupon_discount_sum',\n",
       "       'coupcust_Established_coupon_discount_sum',\n",
       "       'coupcust_Local_other_discount_sum',\n",
       "       'coupcust_Established_other_discount_sum',\n",
       "       'coupcust_Local_coupdisc_price_perc',\n",
       "       'coupcust_Local_otherdisc_price_perc',\n",
       "       'coupcust_Local_discount_price_perc',\n",
       "       'coupcust_Established_coupdisc_price_perc',\n",
       "       'coupcust_Established_otherdisc_price_perc',\n",
       "       'coupcust_Established_discount_price_perc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing model data\n",
    "#columns to drop\n",
    "drop_col = ['age_range', 'marital_status', 'rented', 'family_size', 'no_of_children', 'income_bracket',\n",
    "            'campaign_type', 'camp_start_month', 'camp_end_month', 'camp_start_quarter', 'camp_end_quarter',\n",
    "            'camp_start_year', 'camp_end_year']\n",
    "    \n",
    "tr1 = tr.drop(drop_col, axis='columns')\n",
    "#Merging campaign aggregation data to train dataset based on campaign_id\n",
    "tr1 = tr1.merge(camp_agg, on='campaign_id', how='left').drop(['campaign_id'], axis='columns')\n",
    "#Merging coupon aggregation data to train dataset based on coupon_id\n",
    "tr1 = tr1.merge(coup_agg, on='coupon_id', how='left').drop(['coupon_id'], axis='columns')\n",
    "#Merging customer aggregation data to train dataset based on customer_id\n",
    "model_data = tr1.merge(cust_agg, on='customer_id', how='left').drop(['customer_id', 'coup_Local_brand_nunique',\n",
    "                                                                     'coup_Established_brand_nunique'], axis='columns')\n",
    "\n",
    "#preparing training and validation datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(model_data.drop(['redemption_status'], axis=1),\\\n",
    "                                                    model_data['redemption_status'],\\\n",
    "                                                    test_size=0.25, random_state=100, stratify=model_data['redemption_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "coupcust_Established_coupdisc_quantity_perc     0.058836\n",
      "coupcust_Established_coupon_discount_sum        0.058085\n",
      "coupcust_Established_discount_trans_perc        0.057590\n",
      "coupcust_coupdisc_price_perc                    0.056858\n",
      "coupcust_coupdisc_trans_perc                    0.052620\n",
      "coupcust_trans_count                            0.041921\n",
      "coupcust_coupon_discount_sum                    0.038618\n",
      "coupcust_coupdisc_quantity_sum                  0.037388\n",
      "coupcust_Established_coupdisc_price_perc        0.036280\n",
      "coupcust_quantity_sum                           0.034956\n",
      "coupcust_Established_discount_trans_count       0.027994\n",
      "coupcust_Established_coupdisc_quantity_sum      0.027629\n",
      "coupcust_coupdisc_trans_count                   0.025707\n",
      "coupcust_otherdisc_quantity_perc                0.020779\n",
      "coupcust_items_bought                           0.020369\n",
      "coupcust_selling_price_sum                      0.019787\n",
      "coupcust_Established_otherdisc_quantity_perc    0.016685\n",
      "coupcust_Established_selling_price_sum          0.016300\n",
      "coupcust_Established_coupdisc_trans_count       0.015979\n",
      "coupcust_Established_otherdisc_trans_perc       0.015851\n",
      "coupcust_Established_items_bought               0.015474\n",
      "coupcust_discount_price_perc                    0.014049\n",
      "coupcust_coupdisc_quantity_perc                 0.013695\n",
      "coupcust_Established_discount_quantity_sum      0.013545\n",
      "coupcust_Established_otherdisc_quantity_sum     0.013461\n",
      "dtype: float64\n",
      "0.9917483326527835\n",
      "0.9989411251918016\n",
      "[[57767   462]\n",
      " [    0   547]]\n",
      "0.9978035848032243\n",
      "[[19246   165]\n",
      " [    7   175]]\n"
     ]
    }
   ],
   "source": [
    "#Testing Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=8, random_state=100, n_jobs=-1,\n",
    "                            oob_score=True, class_weight=\"balanced_subsample\")\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Feature Importance:\\n\"+\n",
    "      str(pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False).head(25)))\n",
    "print(rf.oob_score_)\n",
    "print(roc_auc_score(y_train, rf.predict_proba(X_train)[:,1]))\n",
    "print(confusion_matrix(y_train, rf.predict(X_train)))\n",
    "print(roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))\n",
    "print(confusion_matrix(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.06612\n",
      "0:\ttest: 0.9872888\tbest: 0.9872888 (0)\ttotal: 435ms\tremaining: 29m\n",
      "500:\ttest: 0.9988672\tbest: 0.9988779 (492)\ttotal: 2m 25s\tremaining: 16m 56s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9988807751\n",
      "bestIteration = 507\n",
      "\n",
      "Shrink model to first 508 iterations.\n",
      "1.0\n",
      "0.998880775090141\n"
     ]
    }
   ],
   "source": [
    "#Testing Catboost Model\n",
    "cat = CatBoostClassifier(iterations=4000, eval_metric='AUC')\n",
    "fit_params = {'early_stopping_rounds': 100, 'eval_set': [(X_test, y_test)], 'verbose': 500}\n",
    "cat.fit(X_train, y_train, **fit_params)\n",
    "y_pred1_prob = cat.predict_proba(X_train)[:,1]\n",
    "y_pred2_prob = cat.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_train, y_pred1_prob))\n",
    "print(roc_auc_score(y_test, y_pred2_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's auc: 0.999955\ttraining's binary_logloss: 0.00351396\tvalid_1's auc: 0.998914\tvalid_1's binary_logloss: 0.0078413\n",
      "0.9999551980089455\n",
      "0.9989136102164797\n"
     ]
    }
   ],
   "source": [
    "#Testing LGBM Model\n",
    "lgbm = LGBMClassifier(learning_rate=0.05, colsample_bytree=0.5, subsample=0.8, subsample_freq=1,\\\n",
    "                      max_bin=31, n_estimators=4000, min_child_samples= 250, num_leaves=8,\\\n",
    "                      objective='binary',scale_pos_weight=2.5)\n",
    "fit_params = {'early_stopping_rounds': 100, 'eval_set': [(X_train, y_train),\n",
    "                                                         (X_test, y_test)],\n",
    "              'verbose': 500, 'eval_metric': 'auc'}\n",
    "#warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "lgbm.fit(X_train, y_train, **fit_params)\n",
    "y_pred1_prob = lgbm.predict_proba(X_train)[:,1]\n",
    "y_pred2_prob = lgbm.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_train, y_pred1_prob))\n",
    "print(roc_auc_score(y_test, y_pred2_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selected LGBM model based on accuracy and speed\n",
    "#Preparing train and test data  for final output\n",
    "#Preparing model data\n",
    "#columns to drop\n",
    "drop_col = ['age_range', 'marital_status', 'rented', 'family_size', 'no_of_children', 'income_bracket',\n",
    "            'campaign_type', 'camp_start_month', 'camp_end_month', 'camp_start_quarter', 'camp_end_quarter',\n",
    "            'camp_start_year', 'camp_end_year']\n",
    "    \n",
    "tr1 = tr.drop(drop_col, axis='columns')\n",
    "#Merging campaign aggregation data to train dataset based on campaign_id\n",
    "tr1 = tr1.merge(camp_agg, on='campaign_id', how='left').drop(['campaign_id'], axis='columns')\n",
    "#Merging coupon aggregation data to train dataset based on coupon_id\n",
    "tr1 = tr1.merge(coup_agg, on='coupon_id', how='left').drop(['coupon_id'], axis='columns')\n",
    "#Merging customer aggregation data to train dataset based on customer_id\n",
    "model_data = tr1.merge(cust_agg, on='customer_id', how='left').drop(['customer_id', 'coup_Local_brand_nunique',\n",
    "                                                                     'coup_Established_brand_nunique'], axis='columns')\n",
    "\n",
    "X_train, y_train = model_data.drop(['redemption_status'], axis='columns'), model_data['redemption_status']\n",
    "\n",
    "ts1 = ts.drop(drop_col, axis='columns')\n",
    "ts1 = ts1.merge(camp_agg, on='campaign_id', how='left').drop(['campaign_id'], axis='columns')\n",
    "#Merging coupon aggregation data to train dataset based on coupon_id\n",
    "ts1 = ts1.merge(coup_agg, on='coupon_id', how='left').drop(['coupon_id'], axis='columns')\n",
    "#Merging customer aggregation data to train dataset based on customer_id\n",
    "test_data = ts1.merge(cust_agg, on='customer_id', how='left').drop(['customer_id', 'coup_Local_brand_nunique',\n",
    "                                                                     'coup_Established_brand_nunique'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldvalidationLGBM(X_train, y_train, X_test, splits=10):\n",
    "    skf = StratifiedKFold(n_splits=splits, random_state=100, shuffle=True)\n",
    "    y_pred_tot=[]\n",
    "    y_tmp_ts1=[]\n",
    "    y_tmp_pred=[]\n",
    "    \n",
    "    for i, idx in enumerate(skf.split(X_train, y_train)):\n",
    "        X_tr1, y_tr1 = X_train.iloc[idx[0]], y_train.iloc[idx[0]]\n",
    "        X_ts1, y_ts1 = X_train.iloc[idx[1]], y_train.iloc[idx[1]]\n",
    "        \n",
    "        lgbm = LGBMClassifier(learning_rate=0.05, colsample_bytree=0.5, subsample=0.8, subsample_freq=1,\\\n",
    "                      max_bin=63, n_estimators=4000, min_child_samples= 250, num_leaves=8,\\\n",
    "                      objective='binary',scale_pos_weight=1)\n",
    "        #reg_alpha=0.1, reg_lambda=0.1\n",
    "        fit_params = {'early_stopping_rounds': 100, 'eval_set': [(X_tr1, y_tr1), (X_ts1, y_ts1)],\n",
    "                      'verbose': 500, 'eval_metric': 'auc'}\n",
    "        lgbm.fit(X_tr1, y_tr1, **fit_params)\n",
    "        print('Fold :',i+1)\n",
    "        pred_ts1 = lgbm.predict_proba(X_ts1, num_iteration=lgbm.best_iteration_)[:, 1]\n",
    "        print('AUC Score:\\t',roc_auc_score(y_ts1, pred_ts1))\n",
    "        y_tmp_ts1 =np.concatenate((y_tmp_ts1, y_ts1))\n",
    "        y_tmp_pred =np.concatenate((y_tmp_pred, pred_ts1))\n",
    "        pred_test = lgbm.predict_proba(X_test)[:,1]\n",
    "        y_pred_tot.append(pred_test)\n",
    "    \n",
    "    print('Total AUC Score:\\t', roc_auc_score(y_tmp_ts1, y_tmp_pred))\n",
    "    return np.mean(y_pred_tot, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's auc: 0.999616\ttraining's binary_logloss: 0.00543611\tvalid_1's auc: 0.999058\tvalid_1's binary_logloss: 0.00791353\n",
      "Fold : 1\n",
      "AUC Score:\t 0.9990578221930512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's auc: 0.999716\ttraining's binary_logloss: 0.00481732\tvalid_1's auc: 0.998597\tvalid_1's binary_logloss: 0.00939188\n",
      "Fold : 2\n",
      "AUC Score:\t 0.9985973195570707\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's auc: 0.999859\ttraining's binary_logloss: 0.003964\tvalid_1's auc: 0.998993\tvalid_1's binary_logloss: 0.00800056\n",
      "Fold : 3\n",
      "AUC Score:\t 0.9989925402101727\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's auc: 0.999934\ttraining's binary_logloss: 0.00332066\tvalid_1's auc: 0.999008\tvalid_1's binary_logloss: 0.00780869\n",
      "Fold : 4\n",
      "AUC Score:\t 0.9990084196114134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's auc: 0.99978\ttraining's binary_logloss: 0.00454632\tvalid_1's auc: 0.999063\tvalid_1's binary_logloss: 0.00652566\n",
      "Fold : 5\n",
      "AUC Score:\t 0.9990631153267981\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's auc: 0.999969\ttraining's binary_logloss: 0.00275934\tvalid_1's auc: 0.998973\tvalid_1's binary_logloss: 0.0079341\n",
      "Fold : 6\n",
      "AUC Score:\t 0.9989731320531008\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\ttraining's auc: 0.999989\ttraining's binary_logloss: 0.0023387\tvalid_1's auc: 0.999017\tvalid_1's binary_logloss: 0.00785722\n",
      "Fold : 7\n",
      "AUC Score:\t 0.9990172415009916\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's auc: 0.999711\ttraining's binary_logloss: 0.00492048\tvalid_1's auc: 0.999621\tvalid_1's binary_logloss: 0.00508554\n",
      "Fold : 8\n",
      "AUC Score:\t 0.9996206587481385\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's auc: 0.99991\ttraining's binary_logloss: 0.0035765\tvalid_1's auc: 0.998578\tvalid_1's binary_logloss: 0.0083655\n",
      "Fold : 9\n",
      "AUC Score:\t 0.9985779113999986\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's auc: 0.999787\ttraining's binary_logloss: 0.00449867\tvalid_1's auc: 0.999064\tvalid_1's binary_logloss: 0.0073991\n",
      "Fold : 10\n",
      "AUC Score:\t 0.999064414104986\n",
      "Total AUC Score:\t 0.9989697799770881\n"
     ]
    }
   ],
   "source": [
    "#Calculating final prediction based on averaged 10fold predictions\n",
    "pred_lgbm = kfoldvalidationLGBM(X_train, y_train, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prparing final probability data for submission\n",
    "out = pd.DataFrame({'id': ts['id'], 'redemption_status': pred_lgbm})\n",
    "out.to_csv('KFoldLGBM_sub1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
